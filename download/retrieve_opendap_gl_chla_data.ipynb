{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import dl_helper as helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Regional Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU-DO: Define the path_to_pkls_folder (where you stored the mask pkls)\n",
    "group = '7'\n",
    "pkl_folder = f'group_{group}'\n",
    "\n",
    "path_to_pkls_folder = os.path.join('..', 'masks', pkl_folder)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of .pkl files in path_to_pkls_folder\n",
    "mask_filenames = [f for f in os.listdir(path_to_pkls_folder) if f.startswith('masked') and f.endswith('.pkl')]\n",
    "bounding_file = [f for f in os.listdir(path_to_pkls_folder) if f.startswith('bounding') and f.endswith('.pkl')]\n",
    "print(\"Masks: \\t\\t\", mask_filenames)\n",
    "print(\"Bounding box:\\t\", bounding_file)\n",
    "\n",
    "print(\"\\nNote: There should only be one bounding box file. If there are more, please organize your folder into groups.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_arrays = {file.split('.')[-2].split('_')[-1]: pickle.load(open(os.path.join(path_to_pkls_folder, file), 'rb')) for file in mask_filenames}\n",
    "bounding_box = pickle.load(open(os.path.join(path_to_pkls_folder, bounding_file[0]), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons, lats = helper.get_lons_lats(bounding_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that everything is in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.visualize_masks(masked_arrays, lons, lats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define your staging area and destination folder\n",
    "\n",
    "Data is temporarily written to a temporary (staging) location, then is moved to the destination when the writing is complete.\n",
    "\n",
    "Dont use a cloud drive for temp files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'chla_data_group_{group}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_foldername = f'chla_data_group_{group}'\n",
    "\n",
    "destination_path = os.path.join('/Volumes/Seagate 5TB/OceanColour Data/', 'regional_chla_data', destination_foldername)\n",
    "if not os.path.exists(destination_path):\n",
    "    os.makedirs(destination_path)\n",
    "\n",
    "# Dont use an icloud drive folder :( \n",
    "temp_path ='/Users/tara/MacDocuments/MLML/data/staging'\n",
    "if not os.path.exists(temp_path):\n",
    "    os.makedirs(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step, batches_remaining = helper.get_steps_remaining(destination_path)\n",
    "print(\"Batches remaining: \", batches_remaining)\n",
    "print(\"Count: \", len(batches_remaining))\n",
    "\n",
    "for attempt in range(5):\n",
    "    try:\n",
    "        Parallel(n_jobs=-1)(delayed(helper.process_batch)(i, step, bounding_box, lons, lats, destination_path, temp_path) for i in batches_remaining)\n",
    "        break  # If the operation succeeds, break the loop\n",
    "    except Exception as e:\n",
    "        print(f\"Attempt {attempt+1} failed with error: {e}\")\n",
    "        step, batches_remaining = helper.get_steps_remaining(destination_path)\n",
    "else:\n",
    "    print(\"Operation failed after 5 attempts. Quitting.\")\n",
    "\n",
    "\n",
    "steps, batches_remaining = helper.get_steps_remaining(destination_path)\n",
    "if len(batches_remaining) == 0:\n",
    "    print(\"All batches have been processed.\")\n",
    "else:\n",
    "    print(f\"{len(batches_remaining)} batches are still pending.\")\n",
    "    print(\"Please run the cell again to process the remaining batches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_region(i):\n",
    "    # YOU-DO: Define the path_to_pkls_folder (where you stored the mask pkls)\n",
    "    group = str(i)\n",
    "    pkl_folder = f'group_{group}'\n",
    "\n",
    "    path_to_pkls_folder = os.path.join('..', 'masks', pkl_folder) \n",
    "\n",
    "    # get a list of .pkl files in path_to_pkls_folder\n",
    "    bounding_file = [f for f in os.listdir(path_to_pkls_folder) if f.startswith('bounding') and f.endswith('.pkl')]\n",
    "    print(\"Bounding box:\\t\", bounding_file)\n",
    "\n",
    "    bounding_box = pickle.load(open(os.path.join(path_to_pkls_folder, bounding_file[0]), 'rb'))\n",
    "    lons, lats = helper.get_lons_lats(bounding_box)\n",
    "\n",
    "    destination_foldername = f'chla_data_group_{group}'\n",
    "\n",
    "    destination_path = os.path.join('/Volumes/Seagate 5TB/OceanColour Data/', 'regional_chla_data', destination_foldername)\n",
    "    if not os.path.exists(destination_path):\n",
    "        os.makedirs(destination_path)\n",
    "\n",
    "    # Dont use an icloud drive folder :( \n",
    "    temp_path ='/Users/tara/MacDocuments/MLML/data/staging'\n",
    "    if not os.path.exists(temp_path):\n",
    "        os.makedirs(temp_path)\n",
    "\n",
    "    step, batches_remaining = helper.get_steps_remaining(destination_path)\n",
    "    print(\"Batches remaining: \", batches_remaining)\n",
    "    print(\"Count: \", len(batches_remaining))\n",
    "\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            Parallel(n_jobs=-1)(delayed(helper.process_batch)(i, step, bounding_box, lons, lats, destination_path, temp_path) for i in batches_remaining)\n",
    "            break  # If the operation succeeds, break the loop\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1} failed with error: {e}\")\n",
    "            step, batches_remaining = helper.get_steps_remaining(destination_path)\n",
    "    else:\n",
    "        print(\"Operation failed after 5 attempts. Quitting.\")\n",
    "\n",
    "\n",
    "    steps, batches_remaining = helper.get_steps_remaining(destination_path)\n",
    "    if len(batches_remaining) == 0:\n",
    "        print(\"All batches have been processed.\")\n",
    "    else:\n",
    "        print(f\"{len(batches_remaining)} batches are still pending.\")\n",
    "        print(\"Please run the cell again to process the remaining batches.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning group 1...\n",
      "Masks: \t\t ['masked_array_region_034.pkl', 'masked_array_region_000.pkl', 'masked_array_region_001.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n",
      "Beginning group 2...\n",
      "Masks: \t\t ['masked_array_region_003.pkl', 'masked_array_region_002.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n",
      "Beginning group 3...\n",
      "Masks: \t\t ['masked_array_region_006.pkl', 'masked_array_region_005.pkl', 'masked_array_region_004.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n",
      "Beginning group 4...\n",
      "Masks: \t\t ['masked_array_region_009.pkl', 'masked_array_region_008.pkl', 'masked_array_region_007.pkl', 'masked_array_region_010.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n",
      "Beginning group 5...\n",
      "Masks: \t\t ['masked_array_region_012.pkl', 'masked_array_region_011.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n",
      "Beginning group 6...\n",
      "Masks: \t\t ['masked_array_region_013.pkl', 'masked_array_region_014.pkl', 'masked_array_region_015.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n",
      "Beginning group 7...\n",
      "Masks: \t\t ['masked_array_region_018.pkl', 'masked_array_region_017.pkl', 'masked_array_region_016.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n",
      "Beginning group 8...\n",
      "Masks: \t\t ['masked_array_region_019.pkl', 'masked_array_region_020.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n",
      "Beginning group 9...\n",
      "Masks: \t\t ['masked_array_region_021.pkl', 'masked_array_region_022.pkl', 'masked_array_region_023.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n",
      "Beginning group 10...\n",
      "Masks: \t\t ['masked_array_region_024.pkl', 'masked_array_region_025.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n",
      "Beginning group 11...\n",
      "Masks: \t\t ['masked_array_region_027.pkl', 'masked_array_region_026.pkl', 'masked_array_region_028.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n",
      "Beginning group 12...\n",
      "Masks: \t\t ['masked_array_region_030.pkl', 'masked_array_region_031.pkl', 'masked_array_region_029.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n",
      "Beginning group 13...\n",
      "Masks: \t\t ['masked_array_region_033.pkl', 'masked_array_region_032.pkl']\n",
      "Bounding box:\t ['bounding_box.pkl']\n",
      "Batches remaining:  []\n",
      "Count:  0\n",
      "All batches have been processed.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 14):\n",
    "    print(f\"Beginning regional group {i}...\")\n",
    "    download_region(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import time as tm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import time as tm\n",
    "\n",
    "def get_ds(firstday, lastday, bounding_box):\n",
    "    minx_index, maxx_index, miny_index, maxy_index = bounding_box\n",
    "\n",
    "    url = \"https://www.oceancolour.org/thredds/dodsC/CCI_ALL-v6.0-1km-DAILY?lat[\"+maxy_index+\":1:\"+miny_index+\"],lon[\"+minx_index+\":1:\"+maxx_index+\"],chlor_a[\"+firstday+\":1:\"+lastday+\"][\"+maxy_index+\":1:\"+miny_index+\"][\"+minx_index+\":1:\"+maxx_index+\"],time[\"+firstday+\":1:\"+lastday+\"]\"\n",
    "    ds = nc.Dataset(url)\n",
    "\n",
    "    return ds\n",
    "\n",
    "def get_mmddyy(timesinceepoch):\n",
    "    return tm.gmtime(timesinceepoch * 86400)\n",
    "\n",
    "def run_process_batch(i, step, bounding_box, lons, lats, destination_path, staging_path):\n",
    "    firstday = str(i)\n",
    "    lastday = str(i + step - 1)\n",
    "    ds = get_ds(firstday, lastday, bounding_box)\n",
    "    save_batch(ds, firstday, lons, lats, destination_path, staging_path)\n",
    "\n",
    "def save_batch(ds, firstday, lons, lats, destination_path, staging_path):\n",
    "    time_var = ds.variables['time'][:]\n",
    "    \n",
    "    year = get_mmddyy(time_var[0]).tm_year\n",
    "    print(f\"Working on year {year}...\", end=\"\\r\")\n",
    "\n",
    "    # get the current time in seconds\n",
    "    start_time = tm.time()\n",
    "    fp = os.path.join(staging_path, f'chlor_a_data_{firstday}.nc')\n",
    "    with nc.Dataset(fp, 'w') as f:\n",
    "        f.createDimension('time', len(time_var))\n",
    "        f.createDimension('lat', len(lats))\n",
    "        f.createDimension('lon', len(lons))\n",
    "\n",
    "        time_var_out = f.createVariable('time', 'f8', ('time',))\n",
    "        lat_out = f.createVariable('lat', 'f8', ('lat',))\n",
    "        lon_out = f.createVariable('lon', 'f8', ('lon',))\n",
    "        chlor_a_out = f.createVariable('chlor_a', 'f8', ('time', 'lat', 'lon'))\n",
    "\n",
    "        time_var_out[:] = time_var\n",
    "        chlor_a_out[:] = ds.variables['chlor_a'][:]\n",
    "        lat_out[:] = lats\n",
    "        lon_out[:] = lons\n",
    "    \n",
    "    writetime = tm.time()\n",
    "    print(f\"Writing took {writetime - start_time} seconds.\")\n",
    "    # close the ds\n",
    "    ds.close()\n",
    "\n",
    "    movestart = tm.time()\n",
    "    # move the file to the destination folder\n",
    "    shutil.move(fp, os.path.join(destination_path, f'chlor_a_data_{firstday}.nc'))\n",
    "    print(f\"Moving took {tm.time() - movestart} seconds.\")\n",
    "\n",
    "def get_steps_remaining(destination_path):\n",
    "    start, stop, step = 0, 9600, 50\n",
    "\n",
    "    destination_files = [f for f in os.listdir(destination_path) if f.endswith('.nc')]\n",
    "\n",
    "    completed_steps = [int(f.split('.')[0].split('_')[-1]) for f in destination_files]\n",
    "\n",
    "    steps_needed = [i for i in range(start, stop, step) if i not in completed_steps]\n",
    "\n",
    "    # print(\"Batches remaining: \", len(steps_needed))\n",
    "    return step, steps_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step, batches_remaining = get_steps_remaining(destination_path)\n",
    "print(\"Batches remaining: \", batches_remaining)\n",
    "print(\"Count: \", len(batches_remaining))\n",
    "\n",
    "for i in batches_remaining:\n",
    "    print(f\"Processing batch # {i}...\")\n",
    "    run_process_batch(i, step, bounding_box, lons, lats, destination_path, temp_path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenlandchanges",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
