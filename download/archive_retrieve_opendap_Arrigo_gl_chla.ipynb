{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time as tm\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from shapely.geometry import Point, shape\n",
    "\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTENTION\n",
    "\n",
    "**This file has been replaced with a more general pipeline code: _retrive_opendap_gl_chla_means.ipynb_**\n",
    "\n",
    "**This file is no longer used and will be removed in the future.**\n",
    "\n",
    "This file calculates the daily mean over an entire polygon (mask) and stores these daily means as a csv for each region.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Regional Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_pkls_folder = os.path.join('..', 'masks')   \n",
    "\n",
    "# get a list of all files in path_to_pkls_folder with .pkl extension (presumably the masks)\n",
    "pkl_files = [f for f in os.listdir(path_to_pkls_folder) if f.endswith('.pkl')]\n",
    "pkl_files.sort()\n",
    "pkl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pkls = 6\n",
    "# Load the masks\n",
    "masks = []\n",
    "for x in range(num_pkls):\n",
    "    with open(os.path.join(path_to_pkls_folder, 'masked_array'+str(x)+'.pkl'), 'rb') as f:\n",
    "        masks.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the data and get the lat, lons\n",
    "minx_index, maxx_index, miny_index, maxy_index = '11800', '13029', '2894', '2325'   #Arrigo\n",
    "# minx_index, maxx_index, miny_index, maxy_index = '11907', '12484', '2076', '1838' #Disko Bay\n",
    "\n",
    "firstday = '0'\n",
    "lastday = '1'\n",
    "\n",
    "url = \"https://www.oceancolour.org/thredds/dodsC/CCI_ALL-v6.0-1km-DAILY?lat[\"+maxy_index+\":1:\"+miny_index+\"],lon[\"+minx_index+\":1:\"+maxx_index+\"],chlor_a[\"+firstday+\":1:\"+lastday+\"][\"+maxy_index+\":1:\"+miny_index+\"][\"+minx_index+\":1:\"+maxx_index+\"],time[\"+firstday+\":1:\"+lastday+\"]\"\n",
    "ds = nc.Dataset(url)\n",
    "\n",
    "lons = ds.variables['lon'][:]\n",
    "lats = ds.variables['lat'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "minx_index, maxx_index, miny_index, maxy_index = '11800', '13029', '2894', '2325' #Arrigo\n",
    "# minx_index, maxx_index, miny_index, maxy_index = '11907', '12484', '2076', '1838' #Disko Bay\n",
    "\n",
    "def calculate_mean(mask_index, t, step, masks, time, max_chl=50):\n",
    "    mask = masks[mask_index]\n",
    "    data = []\n",
    "\n",
    "    ds = get_url(t, step)\n",
    "    for t in range(len(time)):\n",
    "\n",
    "        if mask_index == 0:\n",
    "            print(f\"{t+1} of {len(time)}\", end=\"\\r\")\n",
    "\n",
    "        chlor_a = np.ma.masked_where(mask.mask, ds.variables['chlor_a'][t].data)    \n",
    "        # chlor_a = np.ma.masked_where(mask.mask, ds[t].data)\n",
    "        chlor_a = np.ma.masked_outside(chlor_a, 0, max_chl)\n",
    "        mean = chlor_a.mean()\n",
    "        data.append({'region': mask_index, 'time': time[t], 'mean': mean})\n",
    "    print()\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def get_url(i, step): \n",
    "    firstday = str(i)\n",
    "    lastday = str(i+(step-1))\n",
    "    url = \"https://www.oceancolour.org/thredds/dodsC/CCI_ALL-v6.0-1km-DAILY?lat[\"+maxy_index+\":1:\"+miny_index+\"],lon[\"+minx_index+\":1:\"+maxx_index+\"],chlor_a[\"+firstday+\":1:\"+lastday+\"][\"+maxy_index+\":1:\"+miny_index+\"][\"+minx_index+\":1:\"+maxx_index+\"],time[\"+firstday+\":1:\"+lastday+\"]\"\n",
    "    return nc.Dataset(url)\n",
    "\n",
    "def process_mask_index(start, step, max_chla, destination_folder):\n",
    "# step = 10\n",
    "    for t in range(start, 10000, step):\n",
    "        # ...\n",
    "        start_time = tm.time()\n",
    "        print(f\"Start time for t={t}: {datetime.datetime.fromtimestamp(start_time).strftime('%H:%M:%S')}\")\n",
    "\n",
    "        ds = get_url(t, step)    \n",
    "        time = ds.variables['time'][:]\n",
    "\n",
    "        results = Parallel(n_jobs=-1, backend=\"threading\")(delayed(calculate_mean)(i, t, step, masks, time, max_chla) for i in range(6))\n",
    "\n",
    "        mid_time = tm.time()\n",
    "        print(f\"finished parallel step: {datetime.datetime.fromtimestamp(mid_time).strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        df = pd.concat(results)\n",
    "        \n",
    "        output_file = os.path.join(destination_folder,  f'mean_chl_{t}_{t+(step-1)}.csv')\n",
    "        df.to_csv(output_file, index=False)\n",
    "        \n",
    "        end_time = tm.time()\n",
    "        print(f\"End time for t={t}: {datetime.datetime.fromtimestamp(end_time).strftime('%H:%M:%S')}\")\n",
    "        # print(f\"Elapsed time for t={t}: {datetime.datetime.fromtimestamp(end_time - start_time).strftime('%H:%M:%S')}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_folder = os.path.join('..', 'means_100')\n",
    "max_chla = 100\n",
    "step = 500\n",
    "\n",
    "# step = 9645-9500\n",
    "start = 9000\n",
    "try:\n",
    "    process_mask_index(start, step, max_chla, destination_folder)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the data in the directory ../means\n",
    "def inspect_data(directory):\n",
    "    directory = '../means/'\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            temp_df = pd.read_csv(filepath)\n",
    "            df = pd.concat([df, temp_df])\n",
    "\n",
    "    df['mean'] = df['mean'].replace('--', np.nan)\n",
    "    df['region'] = df['region'].astype('category')\n",
    "    df['datetime'] = pd.to_datetime(df['time'], unit='D', origin='1970-01-01')\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    df['mean'] = df['mean'].astype(float)\n",
    "\n",
    "    return df\n",
    "   \n",
    "\n",
    "# Print the combined DataFrame\n",
    "# print(inspect_data('../means'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenlandchanges",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
